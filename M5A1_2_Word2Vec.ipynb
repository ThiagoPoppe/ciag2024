{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preâmbulo"
      ],
      "metadata": {
        "id": "n9mq-iru7hni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "1J26rJ5C7eC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq3GjT6YgNMh"
      },
      "source": [
        "# Word2Vec\n",
        "\n",
        "A representação de palavras ou termos por *embeddings* é um dos conceitos mais fundamentais de Deep Learning em Processamento de Linguagem Naturais. O *word2vec*, proposto por Tomas Mikolov et al. no Google em 2013, foi um dos modelos iniciais utilizados para se aprender esse tipo de representação. Apesar de já ser considerado antigo, os conceitos desenvolvidos nas primeiras publicações ainda são úteis para o desenvolvimento de modelos mais avançados.\n",
        "\n",
        "A ideia central do *word2vec* é a de que o significado de uma palavra está diretamente relacionado às palavras ao redor da mesma, ou seja, seu contexto. Por exemplo, podemos imaginar que as palavras que se encaixem em uma frase do tipo \"hoje eu comi ___ no café da manhã\" tenham uma certa proximidade de significado em alguns aspectos, e portanto possuam um grau de similaridade entre seus embeddings.\n",
        "\n",
        "O artigo original propõe duas arquiteturas distintas para isso: **CBOW** (Continuous Bag-of-Words) e **Skip-Gram**.\n",
        "\n",
        "<img width=600 src=\"https://www.researchgate.net/profile/Daniel-Braun-6/publication/326588219/figure/fig1/AS:652185784295425@1532504616288/Continuous-Bag-of-words-CBOW-CB-and-Skip-gram-SG-training-model-illustrations.png\">\n",
        "\n",
        "A arquitetura CBOW recebe como entrada da rede o conjunto de termos que formam o contexto e tenta prever o termo central da sequência. Já a arquitetura Skip-Gram tenta prever os termos do contexto com base na palavra central. Apesar dessa diferença, o objetivo em ambos os casos é gerar os embeddings dos termos. Portanto o que importa para nós no final são as representações aprendidas pelo modelo durante o treinamento e armazenados como parâmetros da rede.\n",
        "\n",
        "Os detalhes da proposta inicial do algoritmo Word2Vec podem ser estudados pelo artigo no [link](https://research.google/pubs/pub41224/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementando\n",
        "\n",
        "Vamos implementar um modelo word2vec utilizando a arquitetura CBOW.\n",
        "\n",
        "Começamos definindo um texto simples para usarmos como dado, e gerando um vocabulário a partir disso."
      ],
      "metadata": {
        "id": "NeaL_Bs8-cJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = \"\"\"we are about to study the idea of a computational process\n",
        "computational processes are abstract beings that inhabit computers\n",
        "as they evolve processes manipulate other abstract things called data\n",
        "the evolution of a process is directed by a pattern of rules\n",
        "called a program people create programs to direct processes in effect\n",
        "we conjure the spirits of the computer with our spells\"\"\".split()\n",
        "\n",
        "# By deriving a set from `raw_text`, we deduplicate the array\n",
        "vocab = set(raw_text)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"Total de %d tokens no vocabulário.\"% vocab_size)"
      ],
      "metadata": {
        "id": "VGVPF7mlNO8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957ab703-9033-432c-88d3-f20193b44d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de 44 tokens no vocabulário.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos então definir dicionários que nos permitam encontrar um índice numérico para cada termo do vocabulário, assim como retornar o termo a partir do índice informado."
      ],
      "metadata": {
        "id": "xnpe7UBB_cdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {word:ix for ix, word in enumerate(vocab)}\n",
        "ix_to_word = {ix:word for ix, word in enumerate(vocab)}\n",
        "\n",
        "print('\\nÍndice da palavra \"abstract\" no dicionário:', word_to_ix[\"abstract\"])\n",
        "print('Palavra do índice 20 do dicionário:', ix_to_word[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hsl47T_e_sED",
        "outputId": "18369093-a35b-420f-ee63-6cc43add648b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Índice da palavra \"abstract\" no dicionário: 40\n",
            "Palavra do índice 20 do dicionário: data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com isso, conseguimos definir uma função que crie vetores (tensores) para um contexto contendo múltiplos termos. Isso é feito simplesmente listando os índices de cada palavra que faz parte do contexto dado como argumento."
      ],
      "metadata": {
        "id": "7DmKK9AV_-m9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsBX3PzCgBWn",
        "outputId": "0fa623ef-ef1b-49ce-a7d4-457ead605e79"
      },
      "source": [
        "def make_context_vector(context, word_to_ix):\n",
        "    idxs = [word_to_ix[w] for w in context]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "make_context_vector(\"we are about to study\".split(), word_to_ix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, 33, 23, 42,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos também os dados, pares contexto-alvo, percorrendo o texto tomando termo a termo como o alvo e as palavras ao redor como seu contexto. No caso, utilizamos uma janela de 2 termos em cada direção para delimitar o contexto."
      ],
      "metadata": {
        "id": "oaxYPJXfBgZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
        "\n",
        "data = []\n",
        "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
        "    context = [raw_text[i-j] for j in range(CONTEXT_SIZE,0,-1)] + [raw_text[i+j] for j in range(1,CONTEXT_SIZE+1)]\n",
        "    target = raw_text[i]\n",
        "    data.append((context, target))\n",
        "\n",
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tmUrbnfAw_a",
        "outputId": "05318c27-6615-4d14-cc09-88327f5d5822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['we', 'are', 'to', 'study'], 'about')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos então a estrutura da rede que utilizaremos. Tudo o que precisamos é de uma camada de Embedding, na qual aprenderemos as representações dos termos, seguida de algumas camadas lineares, as quais farão a previsão da palavra alvo."
      ],
      "metadata": {
        "id": "Y1yrRsPICLXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(CBOW, self).__init__()\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        self.activation_function1 = nn.ReLU()\n",
        "\n",
        "        self.linear2 = nn.Linear(128, vocab_size)\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.tensor([word_to_ix[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "metadata": {
        "id": "R37JJ1iFN4Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instaciamos e treinamos o modelo."
      ],
      "metadata": {
        "id": "Aj5EQsC9FBj7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPYfR7_CftS5"
      },
      "source": [
        "EMDEDDING_DIM = 100\n",
        "\n",
        "model = CBOW(vocab_size, EMDEDDING_DIM)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "#TRAINING\n",
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "\n",
        "    for context, target in data:\n",
        "        context_vector = make_context_vector(context, word_to_ix)\n",
        "\n",
        "        log_probs = model(context_vector)\n",
        "\n",
        "        total_loss += loss_function(log_probs, torch.tensor([word_to_ix[target]]))\n",
        "\n",
        "    #optimize at the end of each epoch\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora podemos testar a rede, fornecendo um contexto e verificando qual palavra o modelo prevê como termo central:"
      ],
      "metadata": {
        "id": "SJD0ljrOFsRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TESTING\n",
        "context = ['people','create','to', 'direct']\n",
        "context_vector = make_context_vector(context, word_to_ix)\n",
        "a = model(context_vector)\n",
        "\n",
        "#Print result\n",
        "print(f'Raw text: \\\"{\" \".join(raw_text)}\\\"\\n')\n",
        "print(f'Context: {context}\\n')\n",
        "print(f'Prediction: \\'{ix_to_word[torch.argmax(a[0]).item()]}\\'')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2st8LrON_H9",
        "outputId": "f8ac5e61-09d8-49fc-b87b-2ed09c81dbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text: \"we are about to study the idea of a computational process computational processes are abstract beings that inhabit computers as they evolve processes manipulate other abstract things called data the evolution of a process is directed by a pattern of rules called a program people create programs to direct processes in effect we conjure the spirits of the computer with our spells\"\n",
            "\n",
            "Context: ['people', 'create', 'to', 'direct']\n",
            "\n",
            "Prediction: 'programs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos também acessar os embeddings de termos individualmente:"
      ],
      "metadata": {
        "id": "xfsplzl7Fi6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_word_emdedding(\"programs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "httad_ELFT4d",
        "outputId": "06bf2236-cdc2-443e-dd7d-cc327dcab42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.9654e-01,  7.6630e-01, -5.4276e-01,  1.8297e+00, -2.3810e+00,\n",
              "         -9.5199e-01, -9.0614e-01,  4.3700e-01,  2.6124e-01,  2.3278e-01,\n",
              "         -1.0762e+00,  6.4728e-03,  1.4939e+00,  1.0228e+00, -6.1191e-02,\n",
              "          1.4968e+00, -1.7783e-01,  1.4811e+00, -1.4848e-02,  1.0777e+00,\n",
              "         -1.0174e+00, -4.6248e-02,  1.0269e+00,  5.3987e-02, -1.2935e+00,\n",
              "          1.3021e+00,  3.5443e-01,  1.6236e+00,  9.0056e-01,  6.1173e-01,\n",
              "         -2.3818e+00, -7.6379e-01,  8.9388e-01, -4.4430e-01, -8.4214e-01,\n",
              "          2.4058e+00, -1.9188e+00, -1.3686e-01, -1.0843e-01,  3.4437e-02,\n",
              "          9.5590e-01, -2.3884e+00,  4.2155e-01, -8.6214e-01, -7.0116e-01,\n",
              "         -1.3507e+00,  3.7163e-01, -1.6404e+00, -4.0019e-01, -1.9817e-02,\n",
              "         -1.5885e-01,  7.7972e-01, -1.4686e+00, -5.1111e-01,  1.1729e-02,\n",
              "         -1.1627e+00,  1.7932e-01, -5.0823e-01, -9.0858e-03,  1.5614e+00,\n",
              "         -1.1414e+00, -1.1708e+00, -6.6843e-01, -7.6404e-02,  5.5218e-02,\n",
              "         -2.1589e+00, -1.9049e-03, -1.0563e+00,  4.4351e-02,  4.5486e-01,\n",
              "          3.4656e-01, -5.6407e-01, -1.0274e+00, -1.1580e+00, -8.7766e-01,\n",
              "         -4.1127e-01, -2.4190e-01,  8.2983e-01, -3.2090e-01, -1.7901e-01,\n",
              "         -5.4901e-01, -7.8403e-01, -2.4362e-01, -8.3569e-01, -4.6439e-01,\n",
              "          4.7888e-01,  8.8209e-01, -1.3882e+00, -1.7897e+00, -1.9022e-01,\n",
              "          1.5345e-02,  6.2744e-01, -4.7458e-01,  7.0269e-01, -7.0238e-01,\n",
              "          9.5125e-01,  1.1269e-01, -2.6251e-01, -6.0144e-01, -1.7461e+00]],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}