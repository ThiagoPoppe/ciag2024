{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV37HIeFpMG2"
      },
      "source": [
        "# Preâmbulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhRxuCa9pMHH"
      },
      "source": [
        "!wget https://www.dropbox.com/s/f8k3xoywff0h3br/questions-words.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXwJx2tzpMHK"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Pacote do Pytorch para processamento de linguagem natural\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKDHOxVApMHL"
      },
      "source": [
        "## Analogias\n",
        "\n",
        "Uma forma intrínseca de avaliar a qualidade de um modelo de linguagem é realizar as chamadas analogias a partir das **representações distribuídas** gerada pelo modelo.\n",
        "\n",
        "Analogias são associações de mesma natureza entre palavras (como flexões de gênero ou número). A geometria dessas associações pode ser visualizada no espaço vetorial onde as palavras são projetadas e, em modelos bem treinados, deve ser possível encontrar semelhanças entre associações de mesma natureza.\n",
        "\n",
        "<img width=600 src=\"https://vecto.space/assets/img/queen.png\">\n",
        "\n",
        "Vamos trabalhar com um popular conjunto de validação através do método de analogias. Ele consiste em pares de associações, onde o primeiro par deve ser usado como referência para completar o segundo par.\n",
        "No exemplo a seguir, Brasil é a palavra que deve ser inferida a partir das três palavras marcadas em negrito.\n",
        "> **Buenos Aires** está para **Argentina** assim como **Brasília** está para <span style=\"color:red\"><u>**Brasil**<u></span>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na prática, essa é a composição do conjunto `questions-words` para validação de modelos de linguagem:"
      ],
      "metadata": {
        "id": "jkTjN5VG9dCq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVP4ftpWpMHN"
      },
      "source": [
        "df = pd.read_csv(\"questions-words.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "_Fih_55T9g72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYImMUqapMHP"
      },
      "source": [
        "## Torchtext\n",
        "**Link para a documentação**: https://pytorch.org/text/stable/index.html.\n",
        "\n",
        "Similar ao `torchvision` para imagens, o pacote `torchtext` facilita o trabalho com dados textuais. Em sua documentação é possível explorar toda a sua gama de possibilidades, entre modelos pré-treinados, métricas, ferramentas, datasets, etc.\n",
        "Aqui vamos conhecer dois elementos importantes para o carregamento de dados.\n",
        "\n",
        "\n",
        "#### Field\n",
        "\n",
        "Objeto que carrega informações de como os dados devem ser processados. A seguir temos a assinatura da sua classe com alguns exemplos de parâmetros que podemos controlar.\n",
        "\n",
        "```python\n",
        "torchtext.data.Field(\n",
        "  dtype=torch.int64,\n",
        "  preprocessing=None,\n",
        "  lower=False,\n",
        "  tokenize=None,\n",
        "  tokenizer_language=\"en\",\n",
        "  include_lengths=False,\n",
        "  batch_first=False,\n",
        "  stop_words=None,\n",
        "  is_target=False,\n",
        "  )\n",
        "```\n",
        "\n",
        "No nosso caso, ambos entrada e saída são sequências de caracteres que passarão pelo mesmo pré-processamento:\n",
        "* `tokenize`: Separação em **tokens**. Por padrão o Field realiza a tokenização `string.split`\n",
        "    * Ex: \"Bom dia Brasil!\" $\\rightarrow$ `[\"Bom\", \"dia\", \"Brasil\", \"!\"]` <br>\n",
        "\n",
        "* `lower`: Conversão para letras minúsculas, assim evitamos duplicidade de palavras (Atenas $\\neq$ atenas).\n",
        "\n",
        "\n",
        "#### TabularDataset\n",
        "\n",
        "É simples carregar dados tabulares utilizando a classe `TabularDataset`. Basta informar:\n",
        "* `path`: O caminho do sistema onde o arquivo se encontra <br>\n",
        "* `format`: A formatação do arquivo (csv, tsv, json) <br>\n",
        "* `fields`: Lista de tuplas `(nome, Field)` representando respectivamente o nome associado a cada coluna da sua tabela e o pré-processamento que os dados devem receber. <br>\n",
        "* `skip_header`: Se o seu arquivo possui uma linha de cabeçalho, você pode removê-la definindo esse parâmetro como `True`.\n",
        "\n",
        "```python\n",
        "torchtext.data.TabularDataset(\n",
        "  path,\n",
        "  format,\n",
        "  fields,\n",
        "  skip_header=False,\n",
        "  )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYuogpWhpMHR"
      },
      "source": [
        "INPUT  = data.Field(lower = True)\n",
        "TARGET = data.Field(lower = True)\n",
        "\n",
        "dataset = data.TabularDataset(\n",
        "    path=\"questions-words.csv\",\n",
        "    format=\"csv\",\n",
        "    fields=[(\"input\", INPUT), (\"target\",TARGET)],\n",
        "    skip_header=True,\n",
        ")\n",
        "\n",
        "for idx, sample in enumerate(dataset):\n",
        "    if idx % 1000 == 0:\n",
        "        print(idx, vars(sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGwBs08spMHS"
      },
      "source": [
        "## Representando os dados como Tensores\n",
        "\n",
        "Para transformar palavras em dados numéricos, uma solução muito utilizada é mapeá-las em um dicionário contendo o vocabulário completo do conjunto.\n",
        "\n",
        "<img src=\"https://static.packt-cdn.com/products/9781786465825/graphics/B05525_03_01.jpg\" width=\"500\">\n",
        "\n",
        "A depender da quantidade de palavras em seu vocabulário, uma representação *One-Hot* pode ser computacionalmente inviável. Por isso utilizamos as **representações distribuídas**, associando vetores densos a cada palavra de nosso dicionário de modo que esse espaço vetorial aproxime palavras que costumam aparecer no mesmo contexto.\n",
        "\n",
        "Vamos explorar algumas maneiras de transformar palavras em representações distribuídas. A principal é a partir de **modelos de linguagem pré-treinados**. Através do pacote `torchtext` é possível consultar todos os modelos ali disponíveis.\n",
        "\n",
        "Algumas nomenclaturas comuns são:\n",
        "\n",
        "* charngram.**100d**: Indica que a representação desse modelo possui 100 dimensões. <br>\n",
        "* glove.**6B**.300d: Indica que o modelo foi treinado com 6 Bilhões de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7WQDq-WpMHT"
      },
      "source": [
        "torchtext.vocab.pretrained_aliases.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ8J8KmQpMHU"
      },
      "source": [
        "Vamos explorar aqui o modelo `glove.6B.100d`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hml-ePoipMHV"
      },
      "source": [
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=100)\n",
        "\n",
        "print(\"\\nUm total de %d tokens são mapeados por esse modelo.\"% len(glove.stoi))\n",
        "print(\"Os 10 primeiros tokens são\", glove.itos[:10])\n",
        "print(\"A dimensionalidade da matriz de representação é:\", glove.vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaAbkR8rpMHW"
      },
      "source": [
        "Usando o objeto do tipo `Field` podemos **construir um vocabulário** contendo somente as palavras (e vetores) relevantes para o nosso problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ2lDVLrpMHX"
      },
      "source": [
        "MAX_VOCAB_SIZE = 1000\n",
        "\n",
        "INPUT.build_vocab(\n",
        "    dataset,\n",
        "    max_size=MAX_VOCAB_SIZE,\n",
        "    vectors=\"glove.6B.100d\",\n",
        ")\n",
        "\n",
        "print(\"Um total de %d tokens são mapeados por esse vocabulário.\"% len(INPUT.vocab.stoi))\n",
        "print(\"Os 10 primeiros tokens são\", INPUT.vocab.itos[:10])\n",
        "\n",
        "print('\\nÍndice da palavra \"fast\" no dicionário:', INPUT.vocab.stoi[\"fast\"])\n",
        "print('Palavra do índice 100 do dicionário:', INPUT.vocab.itos[100])\n",
        "\n",
        "print('\\nDimensionalidade da representação distribuída:', INPUT.vocab.vectors.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwa3xwzcpMHY"
      },
      "source": [
        "## Visualizando o espaço vetorial\n",
        "\n",
        "Como seria impraticável visualizar um espaço vetorial de centenas de dimensões, um artifício muito utilizado é a abordagem de redução de dimensionalidade intitulada **t-distributed Stochastic Neighbor Embedding (tSNE)**.\n",
        "\n",
        "O pacote Scikit-Learn nos traz essa funcionalidade de forma simplificada. Caso queira entender melhor o funcionamento desse método, recomendo a leitura [da documentação](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX25RC1jpMHZ"
      },
      "source": [
        "vectors2d = TSNE(n_components=2).fit_transform(INPUT.vocab.vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Pb-DStpMHZ"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "\n",
        "examples = [11000, 11080, 11102]\n",
        "\n",
        "for example in examples:\n",
        "    print(vars(dataset[example]))\n",
        "\n",
        "    sample = dataset[example]\n",
        "    entrada = sample.input\n",
        "    analogia = sample.target[0]\n",
        "\n",
        "    in_vec  = np.asarray([vectors2d[INPUT.vocab.stoi[e]] for e in entrada])\n",
        "    out_vec = vectors2d[INPUT.vocab.stoi[analogia]]\n",
        "\n",
        "\n",
        "    ax.scatter(in_vec[[0,2], 0], in_vec[[0,2], 1], s=30, color='dodgerblue')\n",
        "    ax.scatter(in_vec[1, 0], in_vec[1, 1], s=30, color='r')\n",
        "    ax.scatter(out_vec[0], out_vec[1], s=30, color='r')\n",
        "\n",
        "    for i, word in enumerate(entrada):\n",
        "        ax.text(in_vec[i,0]+0.2, in_vec[i,1], word, fontsize=14 )\n",
        "    ax.text(out_vec[0]+0.2, out_vec[1], analogia, fontsize=14 )\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfgkGOtJpMHb"
      },
      "source": [
        "## Criando analogias\n",
        "\n",
        "Como dissemos, em um modelo pré-treinado, a geometria do espaço vetorial possui similaridades entre associações de mesma natureza. Podemos explorar essa característica para validar a qualidade de um modelo.\n",
        "\n",
        "Dado um conjunto de 3 palavras da nossa entrada, exemplo: <br>\n",
        "`palavras = [\"man\", \"king\", \"woman\"`]\n",
        "\n",
        "Podemos predizer a associaçao entre o primeiro par de palavras: <br>\n",
        "`associacao = palavra[1] - palavra[0]`\n",
        "\n",
        "e projetar essa associação na terceira palavra: <br>\n",
        "`projecao = palavra[2] + associacao`\n",
        "\n",
        "Essa projeção é um vetor no espaço da representação distribuída que deve estar na vizinhança da analogia que buscamos, nesse caso a palavra `queen`.\n",
        "\n",
        "<img width=400 src=\"https://pbs.twimg.com/media/DKWbi9nXoAAd_un.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZsmhX4rpMHd"
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "\n",
        "    # Retornamos o vetor de embedding associado ao índice de cada um dos tokens\n",
        "    vecs = [embed.vectors[embed.stoi[t]]\n",
        "                for t in [token_a, token_b, token_c]]\n",
        "\n",
        "    # Encontramos a analogia presente entre os vetores apresentados\n",
        "    analogy = vecs[1] - vecs[0] + vecs[2]\n",
        "\n",
        "    # Calculamos a similaridade de cosseno\n",
        "    distances = np.dot(embed.vectors, analogy) / np.linalg.norm(embed.vectors)\n",
        "\n",
        "    # Encontrando o vetor de maior semelhança\n",
        "    best = np.argsort(distances)\n",
        "    best = [embed.itos[best[k]] for k in range(-1, -4, -1) if embed.itos[best[k]] not in [token_a, token_b, token_c]]\n",
        "\n",
        "    return best[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjLPEUe9pMHd"
      },
      "source": [
        "idx = 100\n",
        "print(vars(dataset[idx]))\n",
        "\n",
        "words, analogy = dataset[idx].input, dataset[idx].target\n",
        "prediction = get_analogy(words[0], words[1], words[2], INPUT.vocab)\n",
        "print(f'\\n{words[0].capitalize()} is to {words[1].capitalize()} as {words[2].capitalize()} is to {prediction.capitalize()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahzg8jBnpMHe"
      },
      "source": [
        "## Como aprendemos esses vetores?\n",
        "\n",
        "Acabamos de ver a representação de palaras como ínidices de um vocabulário fixo. Apesar do índice informar a qual palavra estamos nos referindo, ele não incorpora nenhuma informação semântica sobre a palavra, como por exemplo o contexto no qual ela costuma aparecer. Essa representação semântica pode ser aprendida através de uma **camada de Embedding**.  \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1pliMSOcjjOZAiR26ycowSeUJsj5cy9W_)\n",
        "\n",
        "Pense na camada de Embedding como uma tabela $V \\times D$, onde $V$ é o número de palavras do seu vocabulário e $D$ é o número de dimensões do espaço vetorial onde você deseja projetar. Colocando a camada de Embedding no início de sua rede neural, o treinamento vai otimizar os parâmetros da sua tabela encontrando o espaço vetorial que mapeia as relações intrínsecas entre as palavras dentro do contexto da otimização. Internamente, essa tabela nada mais é do que uma matriz de pesos a ser otimizada.\n",
        "\n",
        "\n",
        "No Pytorch, a instância dessa classe recebe como parâmetro ```(vocab_size, embedding_size)```\n",
        "* ```vocab_size```: Tamanho do vocabulário. Note que **não** se trata da dimensionalidade da entrada.\n",
        "* ```embedding_size```: Dimensionalidade do espaço latente. Caso haja o aproveitamento de embeddings pré treinadas deve-se definir a dimensionalidade da camada em função dos pesos que serão importados (ex: glove.6b.100d, ```embedding_size=100```)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFiTmkY5pMHg"
      },
      "source": [
        "class Embed(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size, embedding_size, embedding_weights=None):\n",
        "    super(Embed, self).__init__()\n",
        "\n",
        "    self.embed = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "    if embedding_weights is not None:\n",
        "        self.embed.weight.data.copy_(embedding_weights)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.embed(X)\n",
        "\n",
        "\n",
        "embedding_size = INPUT.vocab.vectors.shape[1]\n",
        "vocab_size     = len(INPUT.vocab)\n",
        "\n",
        "pretrained_embeddings = INPUT.vocab.vectors\n",
        "\n",
        "net = Embed(\n",
        "    vocab_size,\n",
        "    embedding_size,\n",
        "    pretrained_embeddings,\n",
        ")\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e3t6Sc-pMHh"
      },
      "source": [
        "A seguir vamos refazer todos os passos do carregamento de dados para agregá-los em um só lugar. A única novidade aqui é o uso do `Iterator`, equivalente ao `DataLoader` que já conhecemos, mas com alguns facilitadores para trabalhar com dados textuais.\n",
        "\n",
        "```python\n",
        "torchtext.data.Iterator(\n",
        "  dataset,\n",
        "  batch_size,\n",
        "  sort_key=None,\n",
        "  device=None,\n",
        "  shuffle=None,\n",
        "  sort=None,\n",
        "  sort_within_batch=None,\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtXRiKypMHi"
      },
      "source": [
        "#### Passo 1: Defina os fields e o carregamento do dataset\n",
        "INPUT  = data.Field(lower = True)\n",
        "TARGET = data.Field(lower = True)\n",
        "\n",
        "dataset = data.TabularDataset(\n",
        "    \"questions-words.csv\",\n",
        "    format=\"csv\",\n",
        "    fields=[('input', INPUT), ('target',TARGET)],\n",
        "    skip_header=True,\n",
        ")\n",
        "\n",
        "#### Passo 2: Defina o vocabulário **para todos os fields**\n",
        "MAX_VOCAB_SIZE=1000\n",
        "\n",
        "INPUT.build_vocab(\n",
        "    dataset,\n",
        "    max_size=MAX_VOCAB_SIZE,\n",
        "    vectors='glove.6B.100d',\n",
        ")\n",
        "TARGET.build_vocab(\n",
        "    dataset,\n",
        "    max_size=MAX_VOCAB_SIZE,\n",
        "    vectors='glove.6B.100d',\n",
        ")\n",
        "\n",
        "#### Passo 3: Defina o Iterator (nosso loader de batches)\n",
        "loader = data.Iterator(dataset, batch_size=10)\n",
        "\n",
        "for batch in loader:\n",
        "\n",
        "    print(f'Input: {batch.input}\\nshape: {batch.input.shape}')\n",
        "    print(f'\\nTarget: {batch.target}\\nshape: {batch.target.shape}')\n",
        "\n",
        "    inp = batch.input\n",
        "    lab = batch.target\n",
        "\n",
        "    embed = net(inp)\n",
        "    print(f'\\nEmbed shape:{embed.shape}')\n",
        "\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TtLlDUmpMHi"
      },
      "source": [
        "### Um pequeno exercício\n",
        "\n",
        "Refaça as analogias (funções copiadas abaixo) adaptando o código para usar a camada de embedding que definimos acima para adquirir as representações distribuídas de cada palavra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NRMb9MapMHj"
      },
      "source": [
        "def get_analogy(token_a, token_b, token_c, embed):\n",
        "\n",
        "    vecs = # To Do ...\n",
        "\n",
        "    analogy = vecs[1] - vecs[0] + vecs[2]\n",
        "\n",
        "    distances = np.dot(embed, analogy) / np.linalg.norm(embed)\n",
        "    best = np.argsort(distances)\n",
        "    best = [INPUT.vocab.itos[best[k]] for k in range(-1, -4, -1) if INPUT.vocab.itos[best[k]] not in [token_a, token_b, token_c]]\n",
        "\n",
        "    return best[0]\n",
        "\n",
        "idx = 100\n",
        "print(vars(dataset[idx]))\n",
        "words, analogy = dataset[idx].input, dataset[idx].target\n",
        "\n",
        "prediction = get_analogy(words[0], words[1], words[2], net.embed.weight.detach().numpy())\n",
        "print(f'\\n{words[0].capitalize()} is to {words[1].capitalize()} as {words[2].capitalize()} is to {prediction.capitalize()}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}