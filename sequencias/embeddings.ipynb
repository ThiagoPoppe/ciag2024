{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d726cc",
   "metadata": {},
   "source": [
    "# Sequências - Aula Prática 01/04\n",
    "## Embeddings\n",
    "\n",
    "Neste notebook iremos trabalhar um pouco com a parte introdutória de modelos de linguagem, realizando *analogias* a partir de representações distribuídas (*embeddings*) geradas pelo algoritmo de aprendizagem não-supervisionada `GloVe` (*Global Vectors for Word Representation*).\n",
    "> Para saber mais sobre como o `GloVe` funciona, recomendo a leitura do seguinte [notebook](https://colab.research.google.com/github/jaygala24/pytorch-implementations/blob/master/Global%20Vectors%20for%20Word%20Representation.ipynb#scrollTo=oEXgG-hDIMdT). Esse notebook prático não tem como foco explicar como que o algoritmo funciona, mas sim explicar as operações que podemos fazer com as representações distribuídas geradas por algoritmos de *word embedding*.\n",
    "\n",
    "- Este notebook foi inspirado pelos trabalhos disponibilizados nos sites [d2l.ai](https://d2l.ai/chapter_natural-language-processing-pretraining/similarity-analogy.html) e [notebook.community](https://notebook.community/spro/practical-pytorch/glove-word-vectors/glove-word-vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728115f",
   "metadata": {},
   "source": [
    "- **Importante:** caso esteja rodando esse notebook no ambiente da Tatu, favor descomentar e executar a seguinte célula. Caso contrário, basta deixá-la comentada e ignorar a sua execução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de7e6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext nbproxy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887cf1f",
   "metadata": {},
   "source": [
    "Definindo um diretório temporário para salvar dados e eventuais saídas de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26344623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "tmp = tempfile.TemporaryDirectory()\n",
    "\n",
    "print('Nome do diretório temporário:', tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c310f",
   "metadata": {},
   "source": [
    "## Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a1662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join as ospj\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "sns.set_style('dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae90220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definindo se o código será executado na CPU ou na GPU\n",
    "has_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if has_cuda else 'cpu')\n",
    "\n",
    "print('O código será executado em:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1f20f8-663a-4c74-9987-a0fab09e6063",
   "metadata": {},
   "source": [
    "## Analogias\n",
    "\n",
    "Analogias são associações de mesma natureza entre palavras (como flexões de gênero ou número). A geometria dessas associações pode ser visualizada no espaço vetorial onde as palavras são projetadas e, em modelos bem treinados, deve ser possível encontrar semelhanças entre associações de mesma natureza.\n",
    "\n",
    "<img width=600 src=\"../imagens/analogias.png\"/>\n",
    "\n",
    "Ao longo deste notebook, utilizaremos o modelo `GloVe` para realizar a projeção de palavras em um espaço vetorial. Mais especificamente, usaremos o módulo `torchtext` para carregar um modelo pré-treinado em uma base de dados de 6 bilhões de tokens, realizando uma projeção das palavras em um espaço 100 dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45c8b7-c973-461c-b75d-f5a5da3ff3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui temos uma lista de modelos pré-treinados que estão disponíveis na torchtext\n",
    "# No caso do GloVe, a nomenclatura utilizada é: glove.<tamanho-do-corpus>.<dimensão>\n",
    "torchtext.vocab.pretrained_aliases.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a52893-8ac8-4b61-ad19-961e89e32779",
   "metadata": {},
   "source": [
    "### Carregamento de um modelo GloVe pré-treinado\n",
    "\n",
    "Iremos utilizar a classe `torchtext.vocab.GloVe` para carregar um modelo `GloVe` pré-treinado.\n",
    "\n",
    "> O modelo retornado pelo `torchtext` possui alguns atributos, como o dicionário `stoi` (*string* to *int*) para mapear uma palavra para um índice numérico e a lista `itos` (*int* to *string*), mapeando um índice númerico para uma palavra. Além disso, conseguimos acessar a matriz de *embeddings* através do atributo `vectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f45da18-cb6a-4d15-bf1b-1496aa7e9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name='6B', dim=100, cache=tmp.name)\n",
    "\n",
    "random_tokens = np.random.choice(glove.itos, size=5)\n",
    "\n",
    "print('Número de tokens mapeados pelo glove.6B.100d:', len(glove.stoi))\n",
    "print('Aqui temos 5 tokens aleatórios mapeados pelo glove.6B.100d:', random_tokens)\n",
    "print('A dimensionalidade da matriz de embeddings é:', glove.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9afd1-47f4-4503-99d2-326dd9976ebd",
   "metadata": {},
   "source": [
    "### Projeções vetoriais utilizando o GloVe\n",
    "\n",
    "Podemos realizar projeções de palavras utilizando a matriz de *embeddings* computada pelo `glove.6B.100d` através do método `get_vecs_by_tokens`, como visto a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae92be-a232-4e21-acfd-7101cd416ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['man', 'king', 'woman', 'queen']\n",
    "vecs = glove.get_vecs_by_tokens(tokens)\n",
    "\n",
    "plt.matshow(vecs, aspect='auto')\n",
    "plt.yticks(range(4), tokens)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e0fd7-1137-47e2-a5f9-0fe725f1277c",
   "metadata": {},
   "source": [
    "Além disso, podemos visualizar esses vetores no espaço latente para analisar algumas propriedades interessantes. Para tornar a visualização factível, podemos utilizar um algoritmo de redução de dimensionalidade.\n",
    "\n",
    "> Para esse exemplo iremos utilizar o algoritmo de redução de dimensionalidade PCA (*Principal Components Analysis*), devido a uma melhor interpretabilidade para o exemplo escolhido. Porém, é mais comum vermos algoritmos como o t-SNE (*t-distributed Stochastic Neighbor Embedding*), uma vez que este algoritmo preserva a estrutura local do dado original. Para mais detalhes na diferença entre t-SNE e PCA, recomendo a leitura do seguinte [link](https://medium.com/analytics-vidhya/pca-vs-t-sne-17bcd882bf3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aa571-789d-499d-b332-e0314e8437b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tokens = ['man', 'woman', 'king', 'queen', 'brother', 'sister']\n",
    "vecs = glove.get_vecs_by_tokens(tokens)\n",
    "\n",
    "# Calculando a redução de dimensionalidade para um espaço bidimensional\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(vecs.numpy())\n",
    "\n",
    "print('Tamanho dos componentes:', components.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e5224-fe43-4d2a-b443-6752b2a78a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(components[:, 0], components[:, 1])\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    ax.annotate(token, (components[i, 0], components[i, 1]))\n",
    "\n",
    "for i in range(0, len(tokens) - 1, 2):\n",
    "    x = (components[i, 0], components[i+1, 0])\n",
    "    y = (components[i, 1], components[i+1, 1])\n",
    "    ax.plot(x, y, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c15a0b-da3d-4383-953d-daa3561052b7",
   "metadata": {},
   "source": [
    "Note pela imagem acima como a operação vetorial: $(\\overrightarrow{\\text{king}} - \\overrightarrow{\\text{queen}}) + \\overrightarrow{\\text{sister}} \\approx \\overrightarrow{\\text{brother}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14dfc68-e90d-4223-a91a-66bd9d6cb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "king = components[tokens.index('king')]\n",
    "queen = components[tokens.index('queen')]\n",
    "sister = components[tokens.index('sister')]\n",
    "brother = components[tokens.index('brother')]\n",
    "\n",
    "result = (king - queen) + sister\n",
    "print('Vetor resultante:', result)\n",
    "print('Vetor para a palavra \"brother\":', brother)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4046dde3-7b30-4ba8-8b0f-f13f28d59c82",
   "metadata": {},
   "source": [
    "<br> Podemos refazer o plot para verificar onde a posição do vetor resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b52e1e0-32bc-4963-937b-d90d6a054227",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Adicionando o ponto do vetor resultante\n",
    "ax.scatter(result[0], result[1], color='red')\n",
    "ax.annotate('resultante', (result[0], result[1]))\n",
    "\n",
    "ax.scatter(components[:, 0], components[:, 1])\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    ax.annotate(token, (components[i, 0], components[i, 1]))\n",
    "\n",
    "for i in range(0, len(tokens) - 1, 2):\n",
    "    x = (components[i, 0], components[i+1, 0])\n",
    "    y = (components[i, 1], components[i+1, 1])\n",
    "    ax.plot(x, y, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e69816c-412a-4d5d-90ba-cef13b79336d",
   "metadata": {},
   "source": [
    "### Realizando analogias através do GloVe\n",
    "\n",
    "Através de operações vetoriais, como visto anteriormente, somos capazes de criar analogias no espaço latente da nossa representação distribuída, conseguindo responder perguntas como: `rainha está para rei assim como irmã está para ???`.\n",
    "\n",
    "Possuímos diversas estratégias para retornar a palavra correta para tal pergunta. Por exemplo, a partir da imagem da célula anterior, uma possível estratégia é de calcular o top-1 vizinho mais próximo do vetor resultante através de um algoritmo de `KNN`, porém tal estratégia pode ser menos viável em dimensões maiores devido à [maldição da dimensionalidade](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6065061). Para esse notebook, iremos utilizar uma estratégia que envolve a similaridade de cosseno entre os vetores no espaço latente, selecionando como analogia aquele vetor com maior similaridade.\n",
    "\n",
    "A similaridade de cosseno pode ser computada através da seguinte equação, onde temos uma operação de similaridade no numerador (produto interno), dividido pelo produto da norma de cada vetor. Também introduzimos um fator $\\epsilon \\approx 1\\mathrm{e}{-6}$ no denominador como um termo para evitar divisão por zero. A distância, ou similaridade, de cosseno possui imagem entre $[-1, +1]$, onde $-1$ indica que os vetores estão apontados para sentidos opostos; $+1$ indica que os vetores estão apontando para a mesma direção; e $0$ indica que os vetores são perpendiculares.\n",
    "\n",
    "$$\n",
    "\\text{similaridade} = \\frac{\\overrightarrow{x_1} \\cdot \\overrightarrow{x_2}}{\\max(\\lVert \\overrightarrow{x_1} \\rVert_2 * \\lVert \\overrightarrow{x_2} \\rVert_2, \\epsilon)}\n",
    "$$\n",
    "\n",
    "Primeiramente, iremos observar os top vetores retornados pela distância de cosseno a partir de uma *query* (palavra) fornecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd794a-e3b1-473f-a103-8ec3551d115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query, embedding, k=10):\n",
    "    query_vector = embedding.get_vecs_by_tokens(query)\n",
    "    query_vector = query_vector.unsqueeze(dim=0)  # adicionando uma dimensão para casar com as dimensões do embeddings\n",
    "    \n",
    "    cosine = nn.CosineSimilarity(dim=1)\n",
    "    similarities = cosine(query_vector, embedding.vectors)\n",
    "\n",
    "    result = []\n",
    "    values, indices = torch.topk(similarities, k=k+1)  # a query será mais similar com ela mesma, por isso iremos usar k+1\n",
    "    for value, index in zip(values[1:], indices[1:]):\n",
    "        token = embedding.itos[index]\n",
    "        result.append((token, value))\n",
    "\n",
    "    return result\n",
    "\n",
    "similar_tokens = get_similar_tokens('computer', glove, k=5)\n",
    "for i, (token, similarity) in enumerate(similar_tokens):\n",
    "    print(f'{i+1}. {token} -> {similarity:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3688da-cb4d-4df7-a6d8-a2fb409e8cac",
   "metadata": {},
   "source": [
    "<br> Agora iremos utilizar a distância de cosseno para computar analogias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7dbbe2-899e-4026-a6c2-cab8ee93b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token1, token2, token3, embedding):\n",
    "    \"\"\"\n",
    "    A ordem dos tokens passados é: <token1> está para <token2> assim como <token3> está para...\n",
    "    \"\"\"\n",
    "    vecs = embedding.get_vecs_by_tokens([token1, token2, token3])\n",
    "    result = (vecs[1] - vecs[0]) + vecs[2]\n",
    "    result = result.unsqueeze(dim=0)  # adicionando uma dimensão para casar com as dimensões do embeddings\n",
    "\n",
    "    cosine = nn.CosineSimilarity(dim=1)\n",
    "    similarities = cosine(result, embedding.vectors)\n",
    "    analogy = embedding.itos[similarities.argmax()]\n",
    "\n",
    "    return analogy\n",
    "\n",
    "get_analogy('queen', 'king', 'sister', glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e070319-9ddd-49e0-86cc-93b07d48a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b176d-339a-4527-9d99-1d6892e1dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('do', 'did', 'go', glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03e4dc-42ae-401e-b05f-1379089b66c8",
   "metadata": {},
   "source": [
    "## Extra) Utilizando um modelo pré-treinado para uma tarefa de analogias\n",
    "\n",
    "Nessa parte opcional do notebook, iremos ver como podemos usar um modelo pré-treinado de representações distribuídas, como o caso do `GloVe`, e realizar um *fine-tuning* em uma base de dados específica.\n",
    "\n",
    "> No nosso caso, o `GloVe` já é um modelo poderoso o suficiente para realizarmos essas analogias, então essa seção será apenas para ilustrar o procedimento necessário para carregar os pesos de um modelo pré-treinado e como realizar o *fine-tuning* da camada de *embedding*.\n",
    "\n",
    "Antes de continuar com essa parte, iremos carregar os dados e definir um `Dataset` PyTorch customizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea782a6c-5ef7-4327-a748-79f4a830722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P \"$tmp.name\" https://www.dropbox.com/s/f8k3xoywff0h3br/questions-words.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e2c0e-4bea-4ef2-85eb-3d6419ff6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ospj(tmp.name, 'questions-words.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df99a75-55ec-4069-b9a5-881e08fb61db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AnalogiesDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        df_line = self.dataframe.iloc[idx]\n",
    "\n",
    "        # Processando os inputs\n",
    "        inputs = df_line['input'].lower()  # deixando o texto em minúsculo\n",
    "        inputs = inputs.split(' ')  # tokenização simples por palavra\n",
    "\n",
    "        # Processando as labels\n",
    "        labels = df_line['analogy'].lower()  # deixando o texto em minúsculo\n",
    "        \n",
    "        return inputs, labels\n",
    "\n",
    "dataset = AnalogiesDataset(df)\n",
    "print('Tamanho do conjunto de dados:', len(dataset))\n",
    "print('Primeira amostra do conjunto de dados:', dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b666fd15-46a6-4fae-a868-e2eedd3e4ef7",
   "metadata": {},
   "source": [
    "Agora iremos definir o nosso modelo para realizar as analogias. A idéia por trás desse modelo é de utilizar uma camada de *embedding* pré-treinada e utilizar uma camada linear para realizar uma combinação dos vetores de entrada (cálculo da analogia), e indicar qual palavra é mais provável de ser a resposta para a nossa analogia.\n",
    "\n",
    "> Fundamentalmente, estaremos trabalhando com um problema de classificação, onde queremos classificar qual é o *token* mais provável de ser a resposta da nossa analogia. Para isso, utilizaremos como função de perda uma entropia cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fef547-c0bd-4ca3-a36f-859d0c78cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalogyNet(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, embedding_weights: torch.Tensor = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "        # Inicializando os pesos da matriz de embedding\n",
    "        if embedding_weights is not None:\n",
    "            self.embedding.weight.data.copy_(embedding_weights)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.sum(x, dim=0)  # sumarizando os embeddings em um tensor unidimensional\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0f1598-8589-4cbd-b73d-0d3cf2bd80b5",
   "metadata": {},
   "source": [
    "Com os dados e modelo prontos, conseguimos finalmente realizar o *fine-tuning* do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18bf20a-304d-4a0e-8d11-aafe54eca949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = AnalogyNet(vocab_size=len(glove.stoi), embedding_dim=100, embedding_weights=glove.vectors)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "dataset = AnalogiesDataset(df)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for X, y in tqdm(dataset):\n",
    "        # Temos que converter os dados de strings para tensores numéricos\n",
    "        # Para isso, utilizaremos o mapeamento do GloVe, uma vez a nossa matriz de embeddings\n",
    "        # segue a mesma ordem da matriz de embeddings do modelo pré-treindo\n",
    "        X = torch.LongTensor([glove.stoi[token] for token in X])\n",
    "        y = torch.tensor(glove.stoi[y])\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        outputs = model(X)\n",
    "        total_loss += criterion(outputs, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    total_loss /= len(dataset)\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} => mean loss: {total_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93eac5-8611-4dd1-99c9-81058d7e2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_analogy('athens', 'greece', 'bern', glove)  # resposta correta: Suíça"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmony",
   "language": "python",
   "name": "harmony"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
