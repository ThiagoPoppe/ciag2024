{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d726cc",
   "metadata": {},
   "source": [
    "# Sequências - Aula Prática 03/04\n",
    "## RNNs (Recurrent Neural Networks)\n",
    "\n",
    "Neste notebook iremos continuar nossos estudos de redes neurais recorrentes (RNNs), trabalhando dessa vez com modelos `seq2seq` (*sequence-to-sequence*) para construir um tradutor de francês para inglês, uma ideia simples mas poderosa onde duas RNNs trabalham em conjunto para transformar uma sequência em outra.\n",
    "\n",
    "![](../imagens/seq2seq.png)\n",
    "\n",
    "- Esse notebook foi fortemente inspirado no terceiro tutorial da série [NLP From Scratch](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html), disponibilizado no site do PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você estiver rodando esse notebook na Tatu, execute a seguinte célula de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variáveis de ambiente http_proxy e https_proxy configuradas!\n"
     ]
    }
   ],
   "source": [
    "%load_ext nbproxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalando pacotes necessários para realizarmos manipulações e outras operações com texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nltk in /u/ej0f/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.5)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting Unidecode\n",
      "  Obtaining dependency information for Unidecode from https://files.pythonhosted.org/packages/84/b7/6ec57841fb67c98f52fc8e4a2d96df60059637cba077edc569a302a8ffc7/Unidecode-1.3.8-py3-none-any.whl.metadata\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 503 Service Unavailable'))': /packages/84/b7/6ec57841fb67c98f52fc8e4a2d96df60059637cba077edc569a302a8ffc7/Unidecode-1.3.8-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Unidecode\n",
      "\u001b[33m  WARNING: The script unidecode is installed in '/u/ej0f/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed Unidecode-1.3.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071c310f",
   "metadata": {},
   "source": [
    "## Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f2a1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from unidecode import unidecode\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795b6b30-6d1a-4b86-b15f-67e02560c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device escolhido: cuda\n"
     ]
    }
   ],
   "source": [
    "# Verificando se temos CUDA disponível e selecionando o device que será utilizado\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device escolhido:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entendimento da base de dados\n",
    "\n",
    "A base de dados trabalhada durante esse notebook consiste em um arquivo `.txt` que possui pares de frases tanto em inglês quanto em francês, separados por um *tab*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Wow!\tÇa alors !\n",
      "Fire!\tAu feu !\n",
      "Help!\tÀ l'aide !\n",
      "Jump.\tSaute.\n",
      "Stop!\tÇa suffit !\n",
      "Stop!\tStop !\n",
      "Stop!\tArrête-toi !\n"
     ]
    }
   ],
   "source": [
    "!head /pgeoprj/ciag2023/datasets/sequence_datasets/seq2seq/eng-fra.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cefc1bd-91a1-4c01-a1df-8cb2c1ccc31a",
   "metadata": {},
   "source": [
    "## Processamento da base de dados\n",
    "\n",
    "De maneira similar à codificação feita em notebooks anteriores, iremos representar cada palavra de uma linguagem como sendo um índice numérico. Como iremos trabalhar com mais de uma linguagem, é natural criarmos uma classe, denominada de `Language`, para conter os dicionários que irão mapear *tokens* para índices (`token2index`) e índices para *tokens* (`index2token`).A\n",
    "\n",
    "Além disso, manteremos um terceiro dicionário chamado de `token_counter` para manter salvo a frequência de cada *token* nos dados daquela linguagem. Futuramente, iremos utilizar essa frequência para filtrar entradas que contém *tokens* raros, reduzindo assim a gigantesca base de dados para termos algo que executa de forma mais rápida, o que indiretamente também facilita o treinamento da nossa rede.\n",
    "\n",
    "> Note que nesse notebook nós faremos o uso dos *tokens* especiais: **\\<pad\\>**, **\\<sos\\>** e **\\<eos\\>**, definindo de forma manual os índices relacionados com cada *token*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "SOS_INDEX = 1\n",
    "EOS_INDEX = 2\n",
    "\n",
    "class Language:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.token2index = {}\n",
    "        self.token_counter = {}\n",
    "        self.index2token = {PAD_INDEX: '<pad>', SOS_INDEX: '<sos>', EOS_INDEX: '<eos>'}\n",
    "        self.n_tokens = 3  # variável para associar um índice com um novo token\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for token in sentence.split(' '):\n",
    "            self.add_token(token)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        if token not in self.token2index:\n",
    "            self.token_counter[token] = 1\n",
    "            self.token2index[token] = self.n_tokens\n",
    "            self.index2token[self.n_tokens] = token\n",
    "            self.n_tokens += 1\n",
    "        else:\n",
    "            self.token_counter[token] += 1\n",
    "\n",
    "    def trim(self, threshold):        \n",
    "        keep_tokens = []\n",
    "        \n",
    "        for token, count in self.token_counter.items():\n",
    "            if count >= threshold:\n",
    "                keep_tokens.append(token)\n",
    "\n",
    "        ratio = len(keep_tokens) / len(self.token2index)\n",
    "        print(f'Razão de tokens mantidos: {ratio:.4f}')\n",
    "\n",
    "        # Reinicializando dicionários\n",
    "        self.token2index = {}\n",
    "        self.token2count = {}\n",
    "        self.index2token = {PAD_INDEX: '<pad>', SOS_INDEX: '<sos>', EOS_INDEX: '<eos>'}\n",
    "        self.n_tokens = 3\n",
    "\n",
    "        for token in keep_tokens:\n",
    "            self.add_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os textos do arquivo estão todos em [Unicode](https://pt.wikipedia.org/wiki/Unicode). Para simplificar o dado, iremos converter todos os caracteres Unicode em [ASCII](https://pt.wikipedia.org/wiki/ASCII), tornando tudo em caixa baixa e removendo boa parte dos sinais diacríticos através da função `preprocess_string`.\n",
    "\n",
    "> O módulo `re` é para aproveitarmos do poder de utilizar *expressões regulares*, ou do inglês *regular expressions*, permitindo realizar casamento e processamento de *strings* rapidamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kozuscek\n",
      "bei jing\n",
      "francois\n",
      "j ai froid .\n"
     ]
    }
   ],
   "source": [
    "def preprocess_string(string):\n",
    "    ascii = unidecode(string).lower().strip()\n",
    "    ascii = re.sub(r\"([.!?])\", r\" \\1\", ascii)  # colocando um espaço entre texto e pontuação\n",
    "    ascii = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", ascii)  # removendo tudo que não é um token válido\n",
    "    ascii = ascii.strip()\n",
    "\n",
    "    return ascii\n",
    "\n",
    "# Exemplos de uso do preprocess_string\n",
    "print(preprocess_string('kožušček'))\n",
    "print(preprocess_string('François'))\n",
    "print(preprocess_string(\"J'ai froid.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ler os dados do arquivo `.txt`, nós iremos separar o conteúdo em linhas e depois cada linha em pares `(frase1, frase2)`. Como vimos anteriormente, as frases estão separadas por *tab* (`\\t`), onde a primeira frase está em inglês e a segunda em francês. Já que queremos fazer uma tradução no sentido francês $\\rightarrow$ inglês, iremos salvar os pares na ordem inversa, mantendo uma ideia de `(entrada, saída)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b08b11f-e3ff-4a75-9f06-c958a18ad791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pares: 135842\n",
      "Exemplo dos primeiros 3 pares: [('va !', 'go .'), ('cours !', 'run !'), ('courez !', 'run !')]\n"
     ]
    }
   ],
   "source": [
    "def build_pairs():\n",
    "    with open('/pgeoprj/ciag2023/datasets/sequence_datasets/seq2seq/eng-fra.txt', 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "    pairs = []\n",
    "    for line in lines:\n",
    "        sentence1, sentence2 = line.split('\\t')\n",
    "        pairs.append((preprocess_string(sentence2), preprocess_string(sentence1)))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "pairs = build_pairs()\n",
    "print('Número de pares:', len(pairs))\n",
    "print('Exemplo dos primeiros 3 pares:', pairs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos muitos exemplos de frases, e queremos treinar algo relativamente rápido, iremos reduzir o número de sentenças e usar apenas entradas relativamente simples e curtas, com no máximo 10 palavras (incluindo a pontuação final). Além disso, iremos trabalhar apenas com entradas que traduzem para algo do tipo \"*I am*\", \"*He is*\", etc. Tudo isso será condensado na função `filter_pair`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c8a8148e-7955-4599-b63f-c297e9ec2a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo número de pares: 10601\n",
      "Exemplo dos três primeiros novos pares: [('j ai ans .', 'i m .'), ('je vais bien .', 'i m ok .'), ('ca va .', 'i m ok .')]\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    'i am ', 'i m ',\n",
    "    'he is', 'he s ',\n",
    "    'she is', 'she s ',\n",
    "    'you are', 'you re ',\n",
    "    'we are', 'we re ',\n",
    "    'they are', 'they re '\n",
    ")\n",
    "\n",
    "def filter_pair(pair):\n",
    "    text1_length = len(pair[0].split(' '))\n",
    "    text2_length = len(pair[1].split(' '))\n",
    "\n",
    "    return text1_length < MAX_LENGTH and text2_length < MAX_LENGTH and pair[1].startswith(eng_prefixes)\n",
    "\n",
    "pairs = list(filter(filter_pair, pairs))\n",
    "print('Novo número de pares:', len(pairs))\n",
    "print('Exemplo dos três primeiros novos pares:', pairs[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, iremos criar o escopo de cada linguagem que iremos trabalhar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens para linguagem eng: 4350\n",
      "Número de tokens para linguagem fra: 2805\n",
      "Exemplo aleatório de um par: ('nous essayons .', 'we re trying .')\n"
     ]
    }
   ],
   "source": [
    "def build_languages(pairs):\n",
    "    input_language = Language('eng')\n",
    "    output_language = Language('fra')\n",
    "\n",
    "    for sentence1, sentence2 in pairs:\n",
    "        input_language.add_sentence(sentence1)\n",
    "        output_language.add_sentence(sentence2)\n",
    "\n",
    "    return input_language, output_language\n",
    "\n",
    "input_language, output_language = build_languages(pairs)\n",
    "print(f'Número de tokens para linguagem {input_language.name}: {input_language.n_tokens}')\n",
    "print(f'Número de tokens para linguagem {output_language.name}: {output_language.n_tokens}')\n",
    "print('Exemplo aleatório de um par:', random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construção de um `Dataset` e `DataLoader`\n",
    "\n",
    "Finalmente, iremos estudar uma forma de agrupar sequências de tamanhos diferentes em um único *batch* de dados, permitindo trabalhar com `batch_size` em modelos recorrentes.\n",
    "\n",
    "Para isso, faremos um uso extensivo do módulo `torch.nn.utils.rnn`, ou `rnn_utils` como definimos nos imports no começo desse notebook. A partir desse módulo, conseguimos aplicar *padding* em um conjunto de sequências através da função `pad_sequence`, uniformizando o tamanho das sequências. Além disso, PyTorch disponibiliza um tipo específico de dados chamado de `PackedSequence`, destinado exclusivamente para modelos recorrentes, onde podemos usar as funções `pack_padded_sequence` e `pad_packed_sequence`, para converter de tensores para `PackedSequences` e vice-versa.\n",
    "\n",
    "> **Importante:** O uso de `PackedSequences` é interessante quando trabalhamos com dados de tamanho variável, uma vez que os modelos do PyTorch conseguem efetivamente \"pular\" *tokens* `<pad>`, poupando memória e computação!\n",
    "\n",
    "Como estamos trabalhando com sequências de tamanho variável, precisamos \"ensinar\" para o PyTorch como que iremos \"colar\" todas essas sequências para formar um único *batch*. Isso será feito através da definição de uma função chamada `collate_fn` (algo como função de combinação), onde nela usaremos a função `pad_sequence` para conseguir construir um *batch* de dados sem problemas.\n",
    "\n",
    "- Por ora não iremos nos preocupar com a separação entre conjuntos de treino, validação e teste. O objetivo desse notebook é de ensinar como trabalhamos em cenários `seq2seq`, além de como utilizar modelos mais complexos como GRUs e LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_tensors = []\n",
    "    output_tensors = []\n",
    "\n",
    "    for input_tensor, output_tensor in batch:\n",
    "        input_tensors.append(input_tensor)\n",
    "        output_tensors.append(output_tensor)\n",
    "\n",
    "    input_tensors = rnn_utils.pad_sequence(input_tensors, batch_first=False, padding_value=PAD_INDEX)\n",
    "    output_tensors = rnn_utils.pad_sequence(output_tensors, batch_first=False, padding_value=PAD_INDEX)\n",
    "    \n",
    "    return input_tensors, output_tensors\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        pairs = build_pairs()\n",
    "        self.pairs = list(filter(filter_pair, pairs))\n",
    "        self.input_language, self.output_language = build_languages(self.pairs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_sentence, output_sentence = self.pairs[idx]\n",
    "\n",
    "        input_tensor = self.sentence2tensor(input_sentence)\n",
    "        output_tensor = self.sentence2tensor(output_sentence, is_input=False)\n",
    "        \n",
    "        return input_tensor, output_tensor\n",
    "    \n",
    "    def sentence2tensor(self, sentence, is_input = True):\n",
    "        tokens = sentence.split(' ')\n",
    "        tensor = torch.zeros(len(tokens) + 2, dtype=torch.long)  # +2 para comportar <sos> e <eos>\n",
    "\n",
    "        tensor[0] = SOS_INDEX\n",
    "        tensor[-1] = EOS_INDEX\n",
    "\n",
    "        language = self.input_language if is_input else self.output_language\n",
    "        for idx, token in enumerate(tokens):\n",
    "            tensor[idx+1] = language.token2index[token]\n",
    "\n",
    "        return tensor\n",
    "\n",
    "    def tensor2sentence(self, tensor, is_input = True):\n",
    "        language = self.input_language if is_input else self.output_language\n",
    "        return ' '.join(language.index2token[idx.item()] for idx in tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de uma amostra do `TranslationDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de entrada: tensor([ 1,  3, 15, 12, 51,  6,  2])\n",
      "Tensor de saída: tensor([ 1,  3,  4, 34,  5,  2])\n",
      "\n",
      "Frase de entrada: <sos> j en suis certain . <eos>\n",
      "Frase de saída: <sos> i m sure . <eos>\n"
     ]
    }
   ],
   "source": [
    "dataset = TranslationDataset()\n",
    "input_tensor, output_tensor = dataset[42]\n",
    "\n",
    "print('Tensor de entrada:', input_tensor)\n",
    "print('Tensor de saída:', output_tensor)\n",
    "\n",
    "print('\\nFrase de entrada:', dataset.tensor2sentence(input_tensor))\n",
    "print('Frase de saída:', dataset.tensor2sentence(output_tensor, is_input=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de uma amostra do nosso `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da entrada e saída: (torch.Size([11, 32]), torch.Size([11, 32]))\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "input_tensor, output_tensor = next(iter(dataloader))\n",
    "print('Tamanho da entrada e saída:', (input_tensor.shape, output_tensor.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de entrada: tensor([  1, 119, 215, 322, 628,  18,   2,   0,   0,   0,   0])\n",
      "Tensor de saída: tensor([   1,  130,  125,  654,   43, 1582,    5,    2,    0,    0,    0])\n",
      "\n",
      "Frase de entrada: <sos> vous etes tellement adorable ! <eos> <pad> <pad> <pad> <pad>\n",
      "Frase de saída: <sos> you are such a sweetheart . <eos> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "first_input = input_tensor[:, 0]\n",
    "first_output = output_tensor[:, 0]\n",
    "\n",
    "print('Tensor de entrada:', first_input)\n",
    "print('Tensor de saída:', first_output)\n",
    "\n",
    "print('\\nFrase de entrada:', dataset.tensor2sentence(first_input))\n",
    "print('Frase de saída:', dataset.tensor2sentence(first_output, is_input=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo *seq2seq*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba280ce7-abf7-4cb7-b3be-d9fa49f28952",
   "metadata": {},
   "source": [
    "Seguindo as ideias trabalhadas em notebooks passados, precisamos criar um mapeamento entre *tokens* e índices. No nosso caso, o *token* é uma letra do nosso alfabeto. Para isso, iremos construir nosso alfabeto (vocabulário), com base nas letras únicas de todos os nomes da base de dados, e, posteriormente, iremos criar 2 estruturas para realizar tal mapeamento: `token2index` e `index2token`.\n",
    "\n",
    "> Além dos *tokens* obtidos através do texto, é muito comum vermos também outros 3 *tokens* especiais:\n",
    "> - **\\<sos\\>**: abreviação para *start-of-sequence*, ou início de sentença.\n",
    "> - **\\<eos\\>**: abreviação para *end-of-sequence*, ou fim de sentença.\n",
    "> - **\\<pad\\>**: *token* especial destinado para indicar um valor de *pad* na nossa sequência.\n",
    "\n",
    "- Diferentemente do notebook anterior, os *tokens* de **\\<sos\\>** e **\\<eos\\>** serão úteis, uma vez que eles são utilizados em contextos de geração de sentenças. O token **\\<pad\\>** ainda não será utilizado, uma vez que ainda não trabalharemos com *batches* por enquanto.\n",
    "  - Na verdade, iremos utilizar apenas o *token* **\\<eos\\>** no nosso vocabulário, já que forneceremos a primeira letra do nome que queremos gerar para o nosso modelo. Ao utilizar o *token* **\\<sos\\>** no nosso contexto, a nossa rede terá que adivinhar às cegas o primeiro *token* do nosso nome. A utilização de ambos *tokens* de início e fim de sentença são mais vistos em abordagens *seq2seq*, onde produzimos um contexto da frase de entrada, auxiliando a rede a prever o *token* inicial a partir de **\\<sos\\>** com mais garantia de acerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81434dc8-70a4-4f14-bca3-ddfa27ae1d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do alfabeto: 83\n",
      "5 tokens aleatórios do alfabeto: ['t', 'ò', 'G', 'Ś', 'C']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "# Adicionando o token especial <eos>\n",
    "vocabulary.append('<eos>')\n",
    "\n",
    "for names in language_names.values():\n",
    "    for name in names:\n",
    "        for token in name:        \n",
    "            if token not in vocabulary:\n",
    "                vocabulary.append(token)\n",
    "\n",
    "print('Tamanho do alfabeto:', len(vocabulary))\n",
    "print('5 tokens aleatórios do alfabeto:', random.choices(vocabulary, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d38da7e-5302-4d5d-bf54-27531a9dfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token de índice 42: p\n",
      "Índice do token \"<eos>\": 0\n"
     ]
    }
   ],
   "source": [
    "index2token = []\n",
    "token2index = {}\n",
    "\n",
    "for token_idx, token in enumerate(vocabulary):\n",
    "    index2token.append(token)\n",
    "    token2index[token] = token_idx\n",
    "\n",
    "print('Token de índice 42:', index2token[42])\n",
    "print('Índice do token \"<eos>\":', token2index['<eos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73199e9-979e-407f-9716-fec5315ea64a",
   "metadata": {},
   "source": [
    "Agora que temos as estruturas `index2token` e `token2index` bem definidas, conseguimos converter um nome em um tensor de índices numéricos através das funções `token2tensor` e `name2tensor`, como demonstrado a seguir.\n",
    "\n",
    "> **Observação 1:** Criaremos um tensor de tamanho $n \\times 1$, onde $n$ é o tamanho do nome e $1$ o tamanho do nosso *batch*. Para esse notebook, nós não iremos trabalhar com `batch_size > 1`, devido à complicações relacionadas com manipulação de sequências e *padding*. Deixaremos tais assuntos para serem abordados no notebook de `seq2seq`.\n",
    "\n",
    "- Optamos por trocar a ordem padrão das dimensões dos dados em PyTorch, ou seja, com o tamanho do *batch* no começo, para facilitar operações em sequências no futuro, como utilizar `len` para obter o tamanho da sequência e tornar a indexação mais fácil. Na verdade, especificamente para sequências, PyTorch nos dá a opção de colocar o tamanho do *batch* como primeira dimensão do nosso tensor ou na segunda, sendo a primeira o tamanho da nossa sequência. Veremos isso em mais detalhes quando trabalharmos com os modelos recorrentes implementados pelo PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d18b1c-b76f-4032-b7a7-9c5c74a28644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor para o token J: tensor([50])\n",
      "Tensor para o nome Jonas: tensor([[50,  3, 25,  8,  9,  0]])\n"
     ]
    }
   ],
   "source": [
    "def token2tensor(token):\n",
    "    return torch.tensor([token2index[token]], dtype=torch.long)\n",
    "\n",
    "def name2tensor(name):\n",
    "    tensor = torch.zeros((1 + len(name), 1), dtype=torch.long)\n",
    "    \n",
    "    # Adicionando os tokens de fim de sentença\n",
    "    tensor[-1] = token2tensor('<eos>')\n",
    "    \n",
    "    for idx, token in enumerate(name):\n",
    "        tensor[idx] = token2tensor(token)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "name = 'Jonas'\n",
    "print(f'Tensor para o token J:', token2tensor('J'))\n",
    "print(f'Tensor para o nome {name}: {name2tensor(name).T}')  # transposição para fins de print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2462d5c-c8cc-4d34-821f-ece8d2921fbb",
   "metadata": {},
   "source": [
    "Para finalizar essa parte do notebook sobre dados, iremos criar uma função auxiliar `get_random_pair` para selecionar de forma aleatória um par `(idioma, nome)` da nossa base dados. Além disso, tal função irá retornar os tensores relacionados com cada componente do par.\n",
    "\n",
    "- Por ora não iremos nos preocupar com a separação entre conjuntos de treino, validação e teste. O objetivo desse notebook é de ensinar como trabalhamos do zero com geração de sequências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc1a934-7161-46b9-a70d-f55cf23a169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language2tensor(language):\n",
    "    return torch.tensor([languages.index(language)], dtype=torch.long)\n",
    "\n",
    "def get_random_pair():\n",
    "    language = random.choice(languages)\n",
    "    name = random.choice(language_names[language])\n",
    "    name = ''.join(name)  # convertendo lista de caracteres em string\n",
    "\n",
    "    name_tensor = name2tensor(name)\n",
    "    language_tensor = language2tensor(language)\n",
    "\n",
    "    return name, language, name_tensor, language_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e2952b4-92b5-4498-964c-4fea70809a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par selecionado: ('Jon', 'Korean')\n",
      "Tensores do par: (tensor([[50,  3, 25,  0]]), tensor([9]))\n"
     ]
    }
   ],
   "source": [
    "name, language, name_tensor, language_tensor = get_random_pair()\n",
    "\n",
    "print('Par selecionado:', (name, language))\n",
    "print('Tensores do par:', (name_tensor.T, language_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a537a31-45bf-4756-96ff-89ff322cc3d0",
   "metadata": {},
   "source": [
    "## Definição do nosso modelo\n",
    "\n",
    "Como já tratamos a implementação de uma RNN do zero no notebook anterior, iremos utilizar o módulo `nn.RNN` disponibilizado pelo PyTorch. Uma documentação mais extensiva desse módulo pode ser encontrada [aqui](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#rnn). Não iremos utilizar todos os parâmetros customizáveis do módulo, mas iremos explicar eles aqui brevemente.\n",
    "\n",
    "- **`input_size`**: o número de *features* da entrada, no nosso caso por exemplo o tamanho da dimensão de *embedding*.\n",
    "- **`hidden_size`**: o tamanho do estado oculto ($h$) que utilizaremos.\n",
    "- **`num_layers`**: número de camadas recorrentes que iremos \"empilhar\".\n",
    "- **`nonlinearity`**: a camada de ativação não linear utilizado ao longo da recorrência.\n",
    "- **`bias`**: valor *booleano* indicando se queremos ou não utilizar viés nas camadas.\n",
    "- **`batch_first`**: valor *booleano* que permite a gente indicar se queremos trabalhar com dados onde a primeira dimensão é o tamanho do *batch*, nesse caso `batch_first=True`, ou o tamanho da sequência.\n",
    "- **`dropout`**: introduz *dropout* em cada saída da camada recorrente (usado com `num_layers != 1`).\n",
    "- **`bidirectional`**: valor *booleano* que indica se queremos um modelo recorrente bidirecional.\n",
    "\n",
    "Logo abaixo temos um exemplo de utilização do módulo `nn.RNN`. Suponha que após aplicarmos o embedding, nós tenhamos a matriz `X`, cujas dimensões são: $S \\times 1 \\times E$, onde $S$ é o tamanho da sequência e $E$ o tamanho do embedding escolhido.\n",
    "\n",
    "> Para esse exemplo utilizamos: $S = 4$, $E = 2$, $h = 8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da632ad-a1d3-48e1-9ab8-232bd4f350fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do output final: torch.Size([1, 8])\n",
      "Tamanho do hidden final: torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "seq_length = 4\n",
    "embedding_size = 2\n",
    "X = torch.rand(seq_length, 1, embedding_size)  # definindo uma matriz X aleatória apenas para exemplo\n",
    "\n",
    "hidden_size = 8\n",
    "model = nn.RNN(embedding_size, hidden_size, batch_first=False)\n",
    "\n",
    "hidden = None  # nn.RNN irá selecionar h0 como sendo zeros\n",
    "for Xt in X:\n",
    "    outputs, hidden = model(Xt, hidden)\n",
    "\n",
    "print('Tamanho do output final:', outputs.shape)\n",
    "print('Tamanho do hidden final:', hidden.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03679a81-9ad7-4a5e-8373-efcebccbf62c",
   "metadata": {},
   "source": [
    "Como iremos trabalhar com geração de texto, **condicionando** a geração de nomes a partir de um idioma específico, a entrada do nosso modelo no tempo $t$ será a concatenação do *embedding* do *token* atual com o do idioma selecionado. Para isso, teremos dois *embeddings* diferentes: um para a transformação do idioma; e outro para transformação do *token*.\n",
    "\n",
    "Um diagrama do esquema de geração pode ser visto a seguir, note que a nossa arquitetura possui uma modelagem autorregressiva, ou seja, a predição do tempo o $t$ depende das predições do tempo $t-1$, e assim por diante. Nele, o símbolo `&` representa o operador de concatenação das entradas.\n",
    "\n",
    "> A geração da sentença será finalizada quando o modelo prever um *token* de fim de sentença ou quando atingirmos um tamanho predeterminado, forçando assim a adição de um `<eos>` no final da predição.\n",
    "\n",
    "![](../imagens/rnn_autorregressivo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30b8ceb-fdd1-4c1e-b532-eca48a07befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameGenerationModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_languages, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.letter_embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.language_embedding = nn.Embedding(num_languages, embedding_size)\n",
    "\n",
    "        self.rnn = nn.RNN(2 * embedding_size, hidden_size, batch_first=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, vocab_size),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, language, hidden = None):\n",
    "        x = self.letter_embedding(x)\n",
    "        language = self.language_embedding(language)\n",
    "        combined = torch.cat([x, language], dim=-1)  # iremos concatenar ao longo das features\n",
    "\n",
    "        output, hidden = self.rnn(combined, hidden)\n",
    "        output = self.classifier(output)\n",
    "\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959eb62-da34-44f4-adb4-26135c74b472",
   "metadata": {},
   "source": [
    "Exemplo da utilização da rede para o tempo $t = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d276d5d1-60fa-4887-932d-62d8c406d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saída do modelo: tensor([[-4.3127, -4.3729, -4.6023, -5.1198, -4.2001, -4.0599, -4.4466, -4.4725,\n",
      "         -4.4736, -4.1429, -4.3761, -4.0316, -4.5924, -4.5246, -4.8090, -4.5005,\n",
      "         -4.9784, -4.6526, -3.8958, -4.1140, -4.4725, -4.4878, -4.8589, -4.9187,\n",
      "         -4.3690, -4.7872, -4.0835, -4.5726, -4.0561, -4.8965, -4.3949, -4.7226,\n",
      "         -4.4075, -4.5168, -4.6556, -4.1843, -4.2750, -4.4151, -4.5997, -4.1011,\n",
      "         -4.5208, -4.2276, -4.0197, -4.1403, -4.3222, -4.4085, -4.5460, -4.0449,\n",
      "         -4.0477, -4.8675, -4.6912, -4.3057, -4.4953, -4.7843, -4.7493, -4.5717,\n",
      "         -4.5224, -4.4328, -4.3288, -3.9806, -4.5949, -4.6525, -4.2889, -4.1353,\n",
      "         -4.6397, -4.7143, -4.5830, -4.8833, -4.7111, -4.4183, -4.2231, -4.3145,\n",
      "         -4.4207, -4.9036, -3.9180, -4.8810, -4.3709, -4.8032, -4.2959, -4.1839,\n",
      "         -4.6930, -4.2591, -4.5415]], grad_fn=<LogSoftmaxBackward0>)\n",
      "\n",
      "Estado oculto: tensor([[-0.6726, -0.6069,  0.0560,  0.5762, -0.1705, -0.7336, -0.2788,  0.4740,\n",
      "         -0.5599, -0.8633, -0.4429, -0.2815, -0.6277, -0.6130, -0.4235,  0.9508,\n",
      "          0.5481, -0.3706, -0.5038,  0.3215, -0.3713, -0.3320,  0.0025,  0.2024,\n",
      "         -0.2888,  0.3319, -0.5904,  0.4757, -0.8440,  0.1987,  0.2305, -0.0123]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "\n",
      "Próximo token previsto: f\n"
     ]
    }
   ],
   "source": [
    "token = 'J'\n",
    "language = 'English'\n",
    "\n",
    "token_tensor = token2tensor(token)\n",
    "language_tensor = language2tensor(language)\n",
    "\n",
    "model = NameGenerationModel(len(vocabulary), len(languages), embedding_size=16, hidden_size=32)\n",
    "output, hidden = model(token_tensor, language_tensor)\n",
    "\n",
    "print('Saída do modelo:', output)\n",
    "print('\\nEstado oculto:', hidden)\n",
    "\n",
    "next_token = output.argmax()\n",
    "print('\\nPróximo token previsto:', index2token[next_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22bc3e3-237a-4bfd-b882-c1ce63eefe94",
   "metadata": {},
   "source": [
    "## Treinamento do modelo\n",
    "\n",
    "Para o treinamento do modelo generativo, iremos introduzir um novo conceito conhecido como *teacher forcing*, uma estratégia de treinamento de geração de sequências para acelerar a convergência do modelo e garantir estabilidade ao longo do treinamento. A estratégia consiste em utilizar como entrada para o tempo $t$ o *token* real do tempo $t-1$ ao invés da predição do modelo.\n",
    "\n",
    "À primeira vista, essa estratégia pode parecer \"roubada\". Porém, temos que lembrar que o predição do modelo no tempo $t$ é dada pelo *ground truth* do tempo $t-1$ e o estado oculto do modelo que foi atualizado utilizando os *ground truths* do tempo $1$ até $t-2$. Ou seja, o modelo ainda está aprendendo os padrões linguísticos da sentença que lhe foi apresentada, mesmo não usando as suas próprias predições. Uma analogia interessante que podemos fazer com *teacher forcing* é quando vamos fazer uma prova onde a questão **d)** depende da resposta correta da questão **c)** e assim por diante. Se errarmos a questão **a)**, estaremos correndo o risco de errar todas as questões seguintes, mesmo realizando os cálculos corretos. Porém, se no começo de cada questão nós começarmos com a resposta correta da anterior, conseguimos acertar algumas coisas.\n",
    "\n",
    "> **Importante:** Durante a geração de sentenças fora do treino, utilizaremos as predições do modelo ao invés do *ground truth* da sentença, uma vez que tal informação não está disponível. Sendo assim, é esperado observar uma discrepância da performance do modelo. Isso é conhecido na literatura como *exposure bias*, e uma forma simples de mitigar esse efeito é de utilizar *teacher forcing* de maneira probabilística, reduzindo a probabilidade de uso a medida que o modelo prevê novos *tokens* da sentença. Outra estratégia interessante pode ser lida no seguinte [artigo](https://arxiv.org/pdf/2103.11603.pdf), onde os autores propõem fornecer para o modelo um conjunto de palavras similares à do passo $t-1$ ao invés de um único *ground truth*.\n",
    "\n",
    "- Apenas para relembrar: Como o nosso modelo recorrente possui como última camada uma `LogSoftmax`, iremos utilizar a função de perda `nn.NLLLoss` (*negative log-likelihood*), que espera log-probabilidades como saída da rede. Um fato curioso é que `nn.CrossEntropyLoss = LogSoftmax + nn.NLLLoss`, segundo a própria [documentação](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) da `nn.CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75adf7a2-7798-46fa-9861-ec84388ec1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NameGenerationModel(len(vocabulary), len(languages), embedding_size=64, hidden_size=128)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "loss_interval = 1000  # intervalo para salvar a loss média\n",
    "print_interval = 5000  # intervalo para exibir performance da rede\n",
    "num_iterations = 100000\n",
    "\n",
    "# Variáveis para manter o valor da loss ao longo das épocas\n",
    "all_losses = []\n",
    "average_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eece3d-8461-413e-ac80-27b5461a714f",
   "metadata": {},
   "source": [
    "Algo a se notar aqui é que ao invés de usarmos a última saída da rede para calcular a função de custo, como no caso da classificação de nomes, estaremos realizando uma predição a cada instante de tempo. Logo, precisaremos calcular a função de custo para cada predição.\n",
    "\n",
    "Para lidar com isso, o `autograd` do PyTorch permite você apenas somar todos os valores das funções de custo em cada instante de tempo e depois chamar `.backward()` no fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35d9fc1-4995-463e-8684-789e43032da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7163e748cea942ce84c8748ef2ad338b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter [5000/100000] => loss: 9.15676, input ('Dutch', 'Peij'), predicted name: Perne\n",
      "Iter [10000/100000] => loss: 14.03139, input ('Spanish', 'Noguerra'), predicted name: Neneera\n",
      "Iter [15000/100000] => loss: 4.55933, input ('Korean', 'Nam'), predicted name: Ngn\n",
      "Iter [20000/100000] => loss: 8.72096, input ('Polish', 'Bosko'), predicted name: Buwkaw\n",
      "Iter [25000/100000] => loss: 5.04007, input ('Scottish', 'Hay'), predicted name: Hun\n",
      "Iter [30000/100000] => loss: 7.21501, input ('Arabic', 'Deeb'), predicted name: Darr\n",
      "Iter [35000/100000] => loss: 8.76673, input ('German', 'Reiter'), predicted name: Rosser\n",
      "Iter [40000/100000] => loss: 9.02612, input ('Scottish', 'Milne'), predicted name: Mclle\n",
      "Iter [45000/100000] => loss: 5.42725, input ('French', 'Sauvage'), predicted name: Sauvager\n",
      "Iter [50000/100000] => loss: 7.22971, input ('French', 'Harman'), predicted name: Harrin\n",
      "Iter [55000/100000] => loss: 12.83179, input ('Dutch', 'Haanraats'), predicted name: Heandand\n",
      "Iter [60000/100000] => loss: 13.23871, input ('Russian', 'Danchenko'), predicted name: Dalihivkov\n",
      "Iter [65000/100000] => loss: 4.08707, input ('Portuguese', 'Cruz'), predicted name: Caez\n",
      "Iter [70000/100000] => loss: 8.09334, input ('Dutch', 'Agthoven'), predicted name: Anteoeen\n",
      "Iter [75000/100000] => loss: 8.68080, input ('Japanese', 'Takeda'), predicted name: Takama\n",
      "Iter [80000/100000] => loss: 3.24367, input ('Scottish', 'Kerr'), predicted name: Kenr\n",
      "Iter [85000/100000] => loss: 4.29261, input ('Spanish', 'Núñez'), predicted name: Noñaz\n",
      "Iter [90000/100000] => loss: 2.63017, input ('Polish', 'Kozlowski'), predicted name: Kozlowski\n",
      "Iter [95000/100000] => loss: 20.14133, input ('English', 'Chamberlain'), predicted name: Cormsarsnn\n",
      "Iter [100000/100000] => loss: 11.49213, input ('Dutch', 'Krantz'), predicted name: Koun\n"
     ]
    }
   ],
   "source": [
    "for iter in tqdm(range(1, num_iterations + 1)):\n",
    "    name, language, name_tensor, language_tensor = get_random_pair()\n",
    "    \n",
    "    name_tensor = name_tensor.to(device)\n",
    "    language_tensor = language_tensor.to(device)\n",
    "\n",
    "    loss = 0\n",
    "    hidden = None\n",
    "    predicted_tokens = [name[0]]  # o primeiro token é informado a priori\n",
    "\n",
    "    # Iremos iterar sobre todos os tokens até o penúltimo\n",
    "    for idx in range(len(name_tensor) - 1):\n",
    "        output, hidden = model.forward(name_tensor[idx], language_tensor, hidden)  # note que estamos sempre fazendo teacher forcing\n",
    "        loss += criterion(output, name_tensor[idx+1])\n",
    "\n",
    "        # Salvando o nome predito pelo modelo\n",
    "        token = index2token[output.argmax()]\n",
    "        if token != '<eos>':\n",
    "            predicted_tokens.append(token)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    average_loss +=  loss.item() / (len(name_tensor) - 1)\n",
    "    \n",
    "    if iter % print_interval == 0:\n",
    "        predicted_name = ''.join(predicted_tokens)  # convertendo de lista de caracteres para string\n",
    "\n",
    "        print(f'Iter [{iter}/{num_iterations}] => loss: {loss:.5f}, ' \\\n",
    "              f'input {language, name}, predicted name: {predicted_name}')\n",
    "        \n",
    "    if iter % loss_interval == 0:\n",
    "        all_losses.append(average_loss / loss_interval)\n",
    "        average_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde12879-2212-43cd-be8b-79b2056ce5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Evolução da função de perda média ao longo das iterações')\n",
    "plt.xlabel('Intervalo de Salvamento')\n",
    "plt.ylabel('Valor médio')\n",
    "    \n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc696a-94b8-482d-b85c-e28a3abc0128",
   "metadata": {},
   "source": [
    "## Gerando novos nomes\n",
    "\n",
    "Para gerar um novo nome (processo de *sampling*), iremos definir uma função `sample` que, dado um idioma e uma letra inicial, faz com que a rede gere um nome até prever o *token* `<eos>`, ou atingir um tamanho máximo de sentença (nesse caso 20). Nesse caso, usaremos a previsão da rede do tempo $t-1$ para realizar a previsão do tempo $t$.\n",
    "\n",
    "> Teremos a função auxiliar `samples` para realizar múltiplas amostragens da rede dado: um idioma, quais *tokens* iniciais queremos para cada nome e uma função de amostragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d1d04e-e4b4-45ca-be98-75ef27394cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "\n",
    "def sample(language, token):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = None \n",
    "        generated_name = token\n",
    "        language_tensor = language2tensor(language).to(device)\n",
    "\n",
    "        for i in range(max_length):\n",
    "            token_tensor = token2tensor(token).to(device)\n",
    "\n",
    "            output, hidden = model(token_tensor, language_tensor, hidden)\n",
    "            token = index2token[output.argmax()]\n",
    "\n",
    "            if token == '<eos>':\n",
    "                break\n",
    "\n",
    "            generated_name += token\n",
    "\n",
    "        return generated_name\n",
    "    \n",
    "def samples(language, start_tokens, sampling_fn):\n",
    "    print(f'\\n{language}:')\n",
    "    for token in start_tokens:\n",
    "        print(' >', sampling_fn(language, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spanish:\n",
      " > Santiago\n",
      " > Parez\n",
      " > Arino\n",
      "\n",
      "Russian:\n",
      " > Rahilov\n",
      " > Ustelan\n",
      " > Shakhin\n",
      "\n",
      "Chinese:\n",
      " > Chang\n",
      " > Huan\n",
      " > Ing\n"
     ]
    }
   ],
   "source": [
    "samples('Spanish', 'SPA', sample)\n",
    "samples('Russian', 'RUS', sample)\n",
    "samples('Chinese', 'CHI', sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que se executarmos a geração com os mesmos *tokens* iniciais, teremos os mesmos nomes. Isso se deve ao fato de estarmos utilizando uma estratégia de *sampling* determinística, ou seja, escolhendo o próximo *token* como sendo sempre aquele que tem maior probabilidade de ocorrer. Como os pesos da nossa rede estão fixados, sempre teremos os mesmos nomes sendo gerados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spanish:\n",
      " > Santiago\n",
      " > Santiago\n",
      " > Santiago\n",
      "\n",
      "Russian:\n",
      " > Rahilov\n",
      " > Rahilov\n",
      " > Rahilov\n",
      "\n",
      "Chinese:\n",
      " > Chang\n",
      " > Chang\n",
      " > Chang\n"
     ]
    }
   ],
   "source": [
    "samples('Spanish', 'SSS', sample)\n",
    "samples('Russian', 'RRR', sample)\n",
    "samples('Chinese', 'CCC', sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modificar esse comportamento, teremos que introduzir algum viés probabilístico no processo de geração. Existem uma diversidade de estratégias que podemos escolher para introduzir esse viés, como por exemplo:\n",
    "\n",
    "1. Adicionar um ruído na entrada do modelo, alterando um pouco o *embedding* inicial.\n",
    "2. Selecionar os **top-k** *tokens* mais prováveis e realizar uma amostragem desse conjunto.\n",
    "3. Reponderar as probabilidades associadas com cada *token* e realizar uma amostragem com base nessa nova probabilidade (*Temperature Sampling*).\n",
    "\n",
    "Visando simplicidade de implementação e robustez, iremos implementar a segunda estratégia, nomeada de **Top-k Sampling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_sampling(language, token, k=5):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = None \n",
    "        generated_name = token\n",
    "        language_tensor = language2tensor(language).to(device)\n",
    "\n",
    "        for i in range(max_length):\n",
    "            token_tensor = token2tensor(token).to(device)\n",
    "            output, hidden = model(token_tensor, language_tensor, hidden)\n",
    "\n",
    "            # Obtendo as top-k predições da rede\n",
    "            vals, idxs = torch.topk(output[0], k=k)\n",
    "            vals = vals.detach().cpu().numpy()  # covertendo para numpy\n",
    "            idxs = idxs.detach().cpu().numpy()  # convertendo para numpy\n",
    "            \n",
    "            probs = np.e ** vals\n",
    "            probs = probs / probs.sum()\n",
    "\n",
    "            idx = np.random.choice(idxs, p=probs)\n",
    "            token = index2token[idx]\n",
    "            \n",
    "            if token == '<eos>':\n",
    "                break\n",
    "\n",
    "            generated_name += token\n",
    "\n",
    "        return generated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spanish:\n",
      " > Soana\n",
      " > Sieti\n",
      " > Soto\n",
      "\n",
      "Russian:\n",
      " > Rotulail\n",
      " > Raisanev\n",
      " > Reinkhenkov\n",
      "\n",
      "Chinese:\n",
      " > Chian\n",
      " > Chin\n",
      " > Chi\n"
     ]
    }
   ],
   "source": [
    "samples('Spanish', 'SSS', topk_sampling)\n",
    "samples('Russian', 'RRR', topk_sampling)\n",
    "samples('Chinese', 'CCC', topk_sampling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ej0f",
   "language": "python",
   "name": "ej0f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
